namespace Skew {
  enum PassKind {
    LEXING
  }

  class LexingPass : Pass {
    over kind PassKind {
      return .LEXING
    }

    over run(context PassContext) {
      for source in context.inputs {
        context.tokens.append(tokenize(context.log, source))
      }
    }
  }

  class Token {
    var range Range
    var kind TokenKind
  }

  var REMOVE_NEWLINE_BEFORE IntMap<int> = {
    TokenKind.COLON: 0,
    TokenKind.COMMA: 0,
    TokenKind.DOT: 0,
    TokenKind.NEWLINE: 0,
    TokenKind.QUESTION_MARK: 0,
    TokenKind.RIGHT_BRACKET: 0,
    TokenKind.RIGHT_PARENTHESIS: 0,
  }

  # This is the inner loop from "flex", an ancient lexer generator. The output
  # of flex is pretty bad (obfuscated variable names and the opposite of modular
  # code) but it's fast and somewhat standard for compiler design. The code below
  # replaces a simple hand-coded lexer and offers much better performance.
  def tokenize(log Log, source Source) List<Token> {
    var tokens List<Token> = []
    var text = source.contents
    var count = text.count
    var previousKind TokenKind = .NULL
    var stack List<Token> = []

    # For backing up
    var yy_last_accepting_state = 0
    var yy_last_accepting_cpos = 0

    # The current character pointer
    var yy_cp = 0

    while yy_cp < count {
      var yy_current_state = 1 # Reset the NFA
      var yy_bp = yy_cp # The pointer to the beginning of the token
      var yy_act TokenKind = .ERROR

      # Special-case string interpolation
      var c = text[yy_cp]
      if c == '"' || c == ')' && !stack.isEmpty && stack.last.kind == .START_STRING_INTERPOLATION {
        var isStringInterpolation = c == ')'
        yy_cp++
        while yy_cp < count {
          c = text[yy_cp++]
          if c == '"' {
            yy_act = isStringInterpolation ? .END_STRING_INTERPOLATION : .STRING
            break
          }
          if c == '\\' {
            if yy_cp == count {
              break
            }
            c = text[yy_cp++]
            if c == '(' {
              yy_act = isStringInterpolation ? .CONTINUE_STRING_INTERPOLATION : .START_STRING_INTERPOLATION
              break
            }
          }
        }
      }

      # Search for a match
      else {
        while yy_current_state != YY_JAM_STATE {
          if yy_cp >= count {
            break # This prevents syntax errors from causing infinite loops
          }
          c = text[yy_cp]
          var index = c < 127 ? c : 127 # All of the interesting characters are ASCII
          var yy_c = yy_ec[index]
          if yy_accept[yy_current_state] != .YY_INVALID_ACTION {
            yy_last_accepting_state = yy_current_state
            yy_last_accepting_cpos = yy_cp
          }
          while yy_chk[yy_base[yy_current_state] + yy_c] != yy_current_state {
            yy_current_state = yy_def[yy_current_state]
            if yy_current_state >= YY_ACCEPT_LENGTH {
              yy_c = yy_meta[yy_c]
            }
          }
          yy_current_state = yy_nxt[yy_base[yy_current_state] + yy_c]
          yy_cp++
        }

        # Find the action
        yy_act = yy_accept[yy_current_state]
        while yy_act == .YY_INVALID_ACTION {
          # Have to back up
          yy_cp = yy_last_accepting_cpos
          yy_current_state = yy_last_accepting_state
          yy_act = yy_accept[yy_current_state]
        }

        # Ignore whitespace
        if yy_act == .WHITESPACE {
          continue
        }

        # Stop at the end of the file
        if yy_act == .END_OF_FILE {
          break
        }
      }

      # This is the default action in flex, which is usually called ECHO
      if yy_act == .ERROR {
        var iterator = Unicode.StringIterator.INSTANCE.reset(text, yy_bp)
        iterator.nextCodePoint
        var range = Range.new(source, yy_bp, iterator.index)
        log.syntaxErrorExtraData(range, range.toString)
        break
      }

      var token = Token.new(Range.new(source, yy_bp, yy_cp), yy_act)

      # Tokens that start with a greater than may need to be split, potentially multiple times
      var loop = true
      while loop {
        var tokenStartsWithGreaterThan = text[token.range.start] == '>'
        var tokenKind = token.kind
        loop = false

        # Remove tokens from the stack if they aren't working out
        while !stack.isEmpty {
          var top = stack.last
          var topKind = top.kind

          # Stop parsing a type if we find a token that no type expression uses
          if topKind == .LESS_THAN && tokenKind != .LESS_THAN && tokenKind != .IDENTIFIER && tokenKind != .COMMA && tokenKind != .DYNAMIC &&
              tokenKind != .DOT && tokenKind != .LEFT_PARENTHESIS && tokenKind != .RIGHT_PARENTHESIS && !tokenStartsWithGreaterThan {
            stack.removeLast
          } else {
            break
          }
        }

        # Group open
        if tokenKind == .LEFT_PARENTHESIS || tokenKind == .LEFT_BRACE || tokenKind == .LEFT_BRACKET ||
            tokenKind == .LESS_THAN || tokenKind == .START_STRING_INTERPOLATION {
          stack.append(token)
        }

        # Group close
        else if tokenKind == .RIGHT_PARENTHESIS || tokenKind == .RIGHT_BRACE || tokenKind == .RIGHT_BRACKET ||
            tokenKind == .END_STRING_INTERPOLATION || tokenStartsWithGreaterThan {

          # Search for a matching opposite token
          while !stack.isEmpty {
            var top = stack.last
            var topKind = top.kind

            # Don't match ">" that don't work since they are just operators
            if tokenStartsWithGreaterThan && topKind != .LESS_THAN {
              break
            }

            # Consume the current token
            stack.removeLast

            # Stop if it's a match
            if tokenKind == .RIGHT_PARENTHESIS && topKind == .LEFT_PARENTHESIS ||
                tokenKind == .RIGHT_BRACKET && topKind == .LEFT_BRACKET ||
                tokenKind == .RIGHT_BRACE && topKind == .LEFT_BRACE ||
                tokenKind == .END_STRING_INTERPOLATION && topKind == .START_STRING_INTERPOLATION {
              break
            }

            # Special-case angle brackets matches and ignore tentative matches that didn't work out
            if topKind == .LESS_THAN && tokenStartsWithGreaterThan {

              # Break apart operators that start with a closing angle bracket
              if tokenKind != .GREATER_THAN {
                var start = token.range.start
                tokens.append(Token.new(Range.new(source, start, start + 1), .END_PARAMETER_LIST))
                token.range.start = start + 1
                token.kind =
                  tokenKind == .SHIFT_RIGHT ? .GREATER_THAN :
                  tokenKind == .UNSIGNED_SHIFT_RIGHT ? .SHIFT_RIGHT :
                  tokenKind == .GREATER_THAN_OR_EQUAL ? .ASSIGN :
                  tokenKind == .ASSIGN_SHIFT_RIGHT ? .GREATER_THAN_OR_EQUAL :
                  tokenKind == .ASSIGN_UNSIGNED_SHIFT_RIGHT ? .ASSIGN_SHIFT_RIGHT :
                  .NULL
                assert(token.kind != .NULL)
                loop = tokenKind != .GREATER_THAN_OR_EQUAL # Split this token again
              } else {
                token.kind = .END_PARAMETER_LIST
              }

              # Convert the "<" into a bound for type parameter lists
              top.kind = .START_PARAMETER_LIST

              # Stop the search since we found a match
              break
            }
          }
        }
      }

      # Remove newlines based on the previous token to enable line continuations.
      # Make sure to be conservative. We want to be like Python, not like
      # JavaScript ASI! Anything that is at all ambiguous should be disallowed.
      if previousKind == .NEWLINE && token.kind in REMOVE_NEWLINE_BEFORE {
        tokens.removeLast
      }
      previousKind = token.kind

      # Accumulate the token for this iteration
      tokens.append(token)
    }

    # Every token stream ends in END_OF_FILE
    tokens.append(Token.new(Range.new(source, count, count), .END_OF_FILE))

    # Also return preprocessor token presence so the preprocessor can be avoided
    return tokens
  }

  enum TokenKind {
    # Type parameters are surrounded by "<" and ">"
    END_PARAMETER_LIST
    START_PARAMETER_LIST

    # String interpolation looks like "start\( 1 )continue( 2 )end"
    CONTINUE_STRING_INTERPOLATION
    END_STRING_INTERPOLATION
    START_STRING_INTERPOLATION

    def toString string {
      assert(self in _toString)
      return _toString[self]
    }
  }

  namespace TokenKind {
    const _toString IntMap<string> = {
      COMMENT: "comment",
      NEWLINE: "\"\\n\"",
      WHITESPACE: "whitespace",

      AS: "\"as\"",
      BREAK: "\"break\"",
      CASE: "\"case\"",
      CATCH: "\"catch\"",
      CLASS: "\"class\"",
      CONST: "\"const\"",
      CONTINUE: "\"continue\"",
      DEF: "\"def\"",
      DEFAULT: "\"default\"",
      DYNAMIC: "\"dynamic\"",
      ELSE: "\"else\"",
      ENUM: "\"enum\"",
      FALSE: "\"false\"",
      FINALLY: "\"finally\"",
      FOR: "\"for\"",
      IF: "\"if\"",
      IN: "\"in\"",
      INTERFACE: "\"interface\"",
      IS: "\"is\"",
      NAMESPACE: "\"namespace\"",
      NULL: "\"null\"",
      OVER: "\"over\"",
      RETURN: "\"return\"",
      SUPER: "\"super\"",
      SWITCH: "\"switch\"",
      THROW: "\"throw\"",
      TRUE: "\"true\"",
      TRY: "\"try\"",
      VAR: "\"var\"",
      WHILE: "\"while\"",

      ARROW: "\"=>\"",
      ASSIGN: "\"=\"",
      ASSIGN_BITWISE_AND: "\"&=\"",
      ASSIGN_BITWISE_OR: "\"|=\"",
      ASSIGN_BITWISE_XOR: "\"^=\"",
      ASSIGN_DIVIDE: "\"/=\"",
      ASSIGN_INDEX: "\"[]=\"",
      ASSIGN_MINUS: "\"-=\"",
      ASSIGN_MULTIPLY: "\"*=\"",
      ASSIGN_PLUS: "\"+=\"",
      ASSIGN_POWER: "\"**=\"",
      ASSIGN_REMAINDER: "\"%=\"",
      ASSIGN_SHIFT_LEFT: "\"<<=\"",
      ASSIGN_SHIFT_RIGHT: "\">>=\"",
      ASSIGN_UNSIGNED_SHIFT_RIGHT: "\">>>=\"",
      BITWISE_AND: "\"&\"",
      BITWISE_OR: "\"|\"",
      BITWISE_XOR: "\"^\"",
      COLON: "\":\"",
      COMMA: "\",\"",
      COMPARE: "\"<=>\"",
      DECREMENT: "\"--\"",
      DIVIDE: "\"/\"",
      DOT: "\".\"",
      DOT_DOT: "\"..\"",
      DOUBLE_COLON: "\"::\"",
      EQUAL: "\"==\"",
      GREATER_THAN: "\">\"",
      GREATER_THAN_OR_EQUAL: "\">=\"",
      INCREMENT: "\"++\"",
      INDEX: "\"[]\"",
      LEFT_BRACE: "\"{\"",
      LEFT_BRACKET: "\"[\"",
      LEFT_PARENTHESIS: "\"(\"",
      LESS_THAN: "\"<\"",
      LESS_THAN_OR_EQUAL: "\"<=\"",
      LIST: "\"[...]\"",
      LIST_NEW: "\"[new]\"",
      LOGICAL_AND: "\"&&\"",
      LOGICAL_OR: "\"||\"",
      MINUS: "\"-\"",
      MULTIPLY: "\"*\"",
      NOT: "\"!\"",
      NOT_EQUAL: "\"!=\"",
      NULL_DOT: "\"?.\"",
      NULL_JOIN: "\"??\"",
      PLUS: "\"+\"",
      POWER: "\"**\"",
      QUESTION_MARK: "\"?\"",
      REMAINDER: "\"%\"",
      RIGHT_BRACE: "\"}\"",
      RIGHT_BRACKET: "\"]\"",
      RIGHT_PARENTHESIS: "\")\"",
      SEMICOLON: "\";\"",
      SET: "\"{...}\"",
      SET_NEW: "\"{new}\"",
      SHIFT_LEFT: "\"<<\"",
      SHIFT_RIGHT: "\">>\"",
      TILDE: "\"~\"",
      UNSIGNED_SHIFT_RIGHT: "\">>>\"",

      ANNOTATION: "annotation",
      CHARACTER: "character",
      DOUBLE: "double",
      END_OF_FILE: "end of input",
      IDENTIFIER: "identifier",
      INT: "integer",
      INT_BINARY: "integer",
      INT_HEX: "integer",
      INT_OCTAL: "integer",
      STRING: "string",

      END_PARAMETER_LIST: "\">\"",
      START_PARAMETER_LIST: "\"<\"",

      CONTINUE_STRING_INTERPOLATION: "string interpolation",
      END_STRING_INTERPOLATION: "string interpolation",
      START_STRING_INTERPOLATION: "string interpolation",
    }
  }
}
