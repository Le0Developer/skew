namespace Skew {
  enum PassKind {
    LEXING
    TOKEN_PROCESSING
  }

  class LexingPass : Pass {
    over kind PassKind {
      return .LEXING
    }

    over run(context PassContext) {
      for source in context.inputs {
        context.tokens.append(tokenize(context.log, source))
      }
    }
  }

  class TokenProcessingPass : Pass {
    over kind PassKind {
      return .TOKEN_PROCESSING
    }

    over run(context PassContext) {
      for tokens in context.tokens {
        prepareTokens(tokens)
      }
    }
  }

  class Token {
    var range Range
    var kind TokenKind

    def firstCodeUnit int {
      if kind == .END_OF_FILE {
        return 0
      }
      assert(range.start < range.source.contents.count)
      return range.source.contents[range.start]
    }
  }

  var REMOVE_NEWLINE_BEFORE IntMap<int> = {
    TokenKind.COLON: 0,
    TokenKind.COMMA: 0,
    TokenKind.DOT: 0,
    TokenKind.NEWLINE: 0,
    TokenKind.QUESTION_MARK: 0,
    TokenKind.RIGHT_BRACKET: 0,
    TokenKind.RIGHT_PARENTHESIS: 0,
  }

  def prepareTokens(tokens List<Token>) {
    var previousKind TokenKind = .NULL
    var stack List<Token> = []
    var count = 0

    for i in 0..tokens.count {
      var token = tokens[i]

      # Skip null placeholders after tokens that start with a greater than. Each
      # token that may need to split has enough nulls after it for all the pieces.
      # It's a lot faster to remove null gaps during token preparation than to
      # insert pieces in the middle of the token stream (O(n) vs O(n^2)).
      if token == null {
        continue
      }

      # Compress tokens to eliminate unused null gaps
      tokens[count] = token
      count++

      # Tokens that start with a greater than may need to be split
      var tokenKind = token.kind
      var tokenStartsWithGreaterThan = token.firstCodeUnit == '>'

      # Remove tokens from the stack if they aren't working out
      while !stack.isEmpty {
        var top = stack.last
        var topKind = top.kind

        # Stop parsing a type if we find a token that no type expression uses
        if topKind == .LESS_THAN && tokenKind != .LESS_THAN && tokenKind != .IDENTIFIER && tokenKind != .COMMA && tokenKind != .DYNAMIC &&
            tokenKind != .DOT && tokenKind != .LEFT_PARENTHESIS && tokenKind != .RIGHT_PARENTHESIS && !tokenStartsWithGreaterThan {
          stack.removeLast
        } else {
          break
        }
      }

      # Group open
      if tokenKind == .LEFT_PARENTHESIS || tokenKind == .LEFT_BRACE || tokenKind == .LEFT_BRACKET || tokenKind == .LESS_THAN {
        stack.append(token)
      }

      # Group close
      else if tokenKind == .RIGHT_PARENTHESIS || tokenKind == .RIGHT_BRACE || tokenKind == .RIGHT_BRACKET || tokenStartsWithGreaterThan {
        # Search for a matching opposite token
        while !stack.isEmpty {
          var top = stack.last
          var topKind = top.kind

          # Don't match closing angle brackets that don't work since they are just operators
          if tokenStartsWithGreaterThan && topKind != .LESS_THAN {
            break
          }

          # Consume the current token
          stack.removeLast

          # Special-case angle brackets matches
          if topKind == .LESS_THAN {

            # Remove tentative matches that didn't work out
            if !tokenStartsWithGreaterThan {
              continue
            }

            # Break apart operators that start with a closing angle bracket
            if tokenKind != .GREATER_THAN {
              var range = token.range
              var start = range.start
              assert(i + 1 < tokens.count)
              assert(tokens[i + 1] == null)
              assert(
                tokenKind == .ASSIGN_SHIFT_RIGHT ||
                tokenKind == .ASSIGN_UNSIGNED_SHIFT_RIGHT ||
                tokenKind == .GREATER_THAN_OR_EQUAL ||
                tokenKind == .SHIFT_RIGHT ||
                tokenKind == .UNSIGNED_SHIFT_RIGHT)
              tokens[i + 1] = Token.new(Range.new(range.source, start + 1, range.end),
                tokenKind == .SHIFT_RIGHT ? .GREATER_THAN :
                tokenKind == .UNSIGNED_SHIFT_RIGHT ? .SHIFT_RIGHT :
                tokenKind == .GREATER_THAN_OR_EQUAL ? .ASSIGN :
                tokenKind == .ASSIGN_SHIFT_RIGHT ? .GREATER_THAN_OR_EQUAL :
                tokenKind == .ASSIGN_UNSIGNED_SHIFT_RIGHT ? .SHIFT_RIGHT :
                .NULL)
              token.range = Range.new(range.source, start, start + 1)
            }

            # Convert < and > into bounds for type parameter lists
            top.kind = .START_PARAMETER_LIST
            token.kind = .END_PARAMETER_LIST
            tokenKind = .END_PARAMETER_LIST
          }

          # Stop the search since we found a match
          break
        }
      }

      # Remove newlines based on the previous token to enable line continuations.
      # Make sure to be conservative. We want to be like Python, not like
      # JavaScript ASI! Anything that is at all ambiguous should be disallowed.
      if previousKind == .NEWLINE && tokenKind in REMOVE_NEWLINE_BEFORE {
        tokens[count - 2] = token
        count--
      }
      previousKind = tokenKind
    }

    # Trim off the remaining tokens due to null gap removal
    while tokens.count > count {
      tokens.removeLast
    }
  }

  enum TokenKind {
    def toString string {
      assert(self in _toString)
      return _toString[self]
    }
  }

  namespace TokenKind {
    const _toString IntMap<string> = {
      COMMENT: "comment",
      NEWLINE: "\"\\n\"",
      WHITESPACE: "whitespace",

      AS: "\"as\"",
      BREAK: "\"break\"",
      CASE: "\"case\"",
      CATCH: "\"catch\"",
      CLASS: "\"class\"",
      CONST: "\"const\"",
      CONTINUE: "\"continue\"",
      DEF: "\"def\"",
      DEFAULT: "\"default\"",
      DYNAMIC: "\"dynamic\"",
      ELSE: "\"else\"",
      ENUM: "\"enum\"",
      FALSE: "\"false\"",
      FINALLY: "\"finally\"",
      FOR: "\"for\"",
      IF: "\"if\"",
      IN: "\"in\"",
      INTERFACE: "\"interface\"",
      IS: "\"is\"",
      NAMESPACE: "\"namespace\"",
      NULL: "\"null\"",
      OVER: "\"over\"",
      RETURN: "\"return\"",
      SUPER: "\"super\"",
      SWITCH: "\"switch\"",
      THROW: "\"throw\"",
      TRUE: "\"true\"",
      TRY: "\"try\"",
      VAR: "\"var\"",
      WHILE: "\"while\"",

      ARROW: "\"=>\"",
      ASSIGN: "\"=\"",
      ASSIGN_BITWISE_AND: "\"&=\"",
      ASSIGN_BITWISE_OR: "\"|=\"",
      ASSIGN_BITWISE_XOR: "\"^=\"",
      ASSIGN_DIVIDE: "\"/=\"",
      ASSIGN_INDEX: "\"[]=\"",
      ASSIGN_MINUS: "\"-=\"",
      ASSIGN_MULTIPLY: "\"*=\"",
      ASSIGN_PLUS: "\"+=\"",
      ASSIGN_POWER: "\"**=\"",
      ASSIGN_REMAINDER: "\"%=\"",
      ASSIGN_SHIFT_LEFT: "\"<<=\"",
      ASSIGN_SHIFT_RIGHT: "\">>=\"",
      ASSIGN_UNSIGNED_SHIFT_RIGHT: "\">>>=\"",
      BITWISE_AND: "\"&\"",
      BITWISE_OR: "\"|\"",
      BITWISE_XOR: "\"^\"",
      COLON: "\":\"",
      COMMA: "\",\"",
      COMPARE: "\"<=>\"",
      DECREMENT: "\"--\"",
      DIVIDE: "\"/\"",
      DOT: "\".\"",
      DOT_DOT: "\"..\"",
      DOUBLE_COLON: "\"::\"",
      EQUAL: "\"==\"",
      GREATER_THAN: "\">\"",
      GREATER_THAN_OR_EQUAL: "\">=\"",
      INCREMENT: "\"++\"",
      INDEX: "\"[]\"",
      LEFT_BRACE: "\"{\"",
      LEFT_BRACKET: "\"[\"",
      LEFT_PARENTHESIS: "\"(\"",
      LESS_THAN: "\"<\"",
      LESS_THAN_OR_EQUAL: "\"<=\"",
      LIST: "\"[...]\"",
      LIST_NEW: "\"[new]\"",
      LOGICAL_AND: "\"&&\"",
      LOGICAL_OR: "\"||\"",
      MINUS: "\"-\"",
      MULTIPLY: "\"*\"",
      NOT: "\"!\"",
      NOT_EQUAL: "\"!=\"",
      NULL_DOT: "\"?.\"",
      NULL_JOIN: "\"??\"",
      PLUS: "\"+\"",
      POWER: "\"**\"",
      QUESTION_MARK: "\"?\"",
      REMAINDER: "\"%\"",
      RIGHT_BRACE: "\"}\"",
      RIGHT_BRACKET: "\"]\"",
      RIGHT_PARENTHESIS: "\")\"",
      SEMICOLON: "\";\"",
      SET: "\"{...}\"",
      SET_NEW: "\"{new}\"",
      SHIFT_LEFT: "\"<<\"",
      SHIFT_RIGHT: "\">>\"",
      TILDE: "\"~\"",
      UNSIGNED_SHIFT_RIGHT: "\">>>\"",

      ANNOTATION: "annotation",
      CHARACTER: "character",
      DOUBLE: "double",
      END_OF_FILE: "end of input",
      IDENTIFIER: "identifier",
      INT: "integer",
      INT_BINARY: "integer",
      INT_HEX: "integer",
      INT_OCTAL: "integer",
      STRING: "string",
    }
  }
}
